{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from functools import reduce\n",
    "from unicodedata import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv('data/estadao_noticias_eleicao.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join do conteúdo\n",
    "Juntando os títulos das notícias com seus respectivos conteúdos,\n",
    "para posteriomente facilitar a tokenização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpar_texto(texto):\n",
    "    pattern = re.compile('[^a-zA-Z0-9 ]')\n",
    "    texto = normalize('NFKD', texto).encode('ASCII', 'ignore').decode('ASCII')\n",
    "    return pattern.sub(' ', texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "materias = dados.titulo + \" \" + dados.subTitulo +  \" \" + dados.conteudo\n",
    "materias = materias.apply(lambda texto: \"\" if isinstance(texto, float) else limpar_texto(texto))\n",
    "ids = dados.idNoticia\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizando conteúdo\n",
    "Criando tokens com cada palavra do texto para que posteriormente possam ser indexadas e associadas aos respectivos ids das notícias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = materias.apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexando tokens\n",
    "Criando indices invertidos com os tokens para poder aplicar os métodos de busca "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = {}\n",
    "\n",
    "# for i in range(len(tokens)):\n",
    "#     id_noticia = ids[i]\n",
    "#     palavras = tokens[i]\n",
    "#     for palavra in palavras:\n",
    "#         palavra = Termo(palavra.lower())\n",
    "#         if palavra not in index:\n",
    "#             index[palavra] = []\n",
    "        \n",
    "#         id_rec = reduce(lambda found, id_not: id_not if id_not[1] == id_noticia else found, index.get(palavra, []), None)\n",
    "        \n",
    "#         if not id_rec:\n",
    "#             index[palavra].append((1, id_noticia))\n",
    "#         else:\n",
    "#             index_id = index[palavra].index(id_rec)\n",
    "#             index[palavra][index_id] = (id_rec[0] + 1, id_rec[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = {}\n",
    "\n",
    "for i in range(len(tokens)):\n",
    "    id_noticia = ids[i]\n",
    "    palavras = tokens[i]\n",
    "    for palavra in palavras:\n",
    "        palavra = palavra.lower()\n",
    "        if palavra not in index:\n",
    "            index[palavra] = (0, [])\n",
    "        \n",
    "        id_rec = reduce(lambda found, id_not: id_not if id_not[1] == id_noticia else found, index.get(palavra, (-1, []))[1], None)\n",
    "        \n",
    "        if not id_rec:\n",
    "            docs = index[palavra]\n",
    "            docs[1].append((1, id_noticia))\n",
    "            index[palavra] = (docs[0] + 1, docs[1])\n",
    "        else:\n",
    "            docs = index[palavra]\n",
    "            index_id = docs[1].index(id_rec)\n",
    "            docs[1][index_id] = (id_rec[0] + 1, id_rec[1])\n",
    "            index[palavra] = (docs[0] + 1, docs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50019\n"
     ]
    }
   ],
   "source": [
    "print(len(index))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
