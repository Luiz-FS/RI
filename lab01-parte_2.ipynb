{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import os\n",
    "from functools import reduce\n",
    "from unicodedata import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv('data/estadao_noticias_eleicao.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join do conteúdo\n",
    "Juntando os títulos das notícias com seus respectivos conteúdos,\n",
    "para posteriomente facilitar a tokenização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpar_texto(texto):\n",
    "    pattern = re.compile('[^a-zA-Z0-9 ]')\n",
    "    texto = normalize('NFKD', texto).encode('ASCII', 'ignore').decode('ASCII')\n",
    "    return pattern.sub(' ', texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "materias = dados.titulo + \" \" + dados.subTitulo +  \" \" + dados.conteudo\n",
    "materias = materias.apply(lambda texto: \"\" if isinstance(texto, float) else limpar_texto(texto))\n",
    "ids = dados.idNoticia\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizando conteúdo\n",
    "Criando tokens com cada palavra do texto para que posteriormente possam ser indexadas e associadas aos respectivos ids das notícias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = materias.apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexando tokens\n",
    "Criando indices invertidos com os tokens para poder aplicar os métodos de busca "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Termo(object):\n",
    "    def __init__(self, termo):\n",
    "        self.termo = termo\n",
    "        self.idf = 1\n",
    "        \n",
    "    def __hash__(self):\n",
    "        return hash(self.termo)\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, str):\n",
    "            return self.termo == other\n",
    "        return self.termo == other.termo\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Termo: %s\" %(self.termo) + os.linesep + \"Idf: %d\" %(self.idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = {}\n",
    "\n",
    "# for i in range(len(tokens)):\n",
    "#     id_noticia = ids[i]\n",
    "#     palavras = tokens[i]\n",
    "#     for palavra in palavras:\n",
    "#         palavra = Termo(palavra.lower())\n",
    "#         if palavra not in index:\n",
    "#             index[palavra] = []\n",
    "        \n",
    "#         id_rec = reduce(lambda found, id_not: id_not if id_not[1] == id_noticia else found, index.get(palavra, []), None)\n",
    "        \n",
    "#         if not id_rec:\n",
    "#             index[palavra].append((1, id_noticia))\n",
    "#         else:\n",
    "#             index_id = index[palavra].index(id_rec)\n",
    "#             index[palavra][index_id] = (id_rec[0] + 1, id_rec[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c92cb2b67b8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpalavra\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mindex_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_rec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mdocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mid_rec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_rec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpalavra\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "index = {}\n",
    "\n",
    "for i in range(len(tokens)):\n",
    "    id_noticia = ids[i]\n",
    "    palavras = tokens[i]\n",
    "    for palavra in palavras:\n",
    "        palavra = palavra.lower()\n",
    "        if palavra not in index:\n",
    "            index[palavra] = (0, [])\n",
    "        \n",
    "        id_rec = reduce(lambda found, id_not: id_not if id_not[1] == id_noticia else found, index.get(palavra, (-1, []))[1], None)\n",
    "        \n",
    "        if not id_rec:\n",
    "            docs = index[palavra]\n",
    "            docs[1].append((1, id_noticia))\n",
    "            index[palavra] = (docs[0] + 1, docs[1])\n",
    "        else:\n",
    "            docs = index[palavra]\n",
    "            index_id = docs[1].index(id_rec)\n",
    "            docs[1][index_id] = (id_rec[0] + 1, id_rec[1])\n",
    "            index[palavra] = (docs[0] + 1, docs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(index))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
