{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import math\n",
    "import ast\n",
    "from unicodedata import normalize\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gabarito = pd.read_csv('gabarito/gabarito.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_str_in_lst(lista):\n",
    "    return ast.literal_eval(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gabarito.google = gabarito.google.apply(convert_str_in_lst)\n",
    "gabarito.busca_binaria = gabarito.busca_binaria.apply(convert_str_in_lst)\n",
    "gabarito.tf = gabarito.tf.apply(convert_str_in_lst)\n",
    "gabarito.tfidf = gabarito.tfidf.apply(convert_str_in_lst)\n",
    "gabarito.bm25 = gabarito.bm25.apply(convert_str_in_lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv('data/estadao_noticias_eleicao.csv')\n",
    "dados = dados.replace(np.nan, '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join do conteúdo\n",
    "Juntando os títulos das notícias com seus respectivos conteúdos,\n",
    "para posteriomente facilitar a tokenização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpar_texto(texto):\n",
    "    pattern = re.compile('[^a-zA-Z0-9 ]')\n",
    "    texto = normalize('NFKD', texto).encode('ASCII', 'ignore').decode('ASCII')\n",
    "    return pattern.sub(' ', texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "materias = dados.titulo + \" \" + dados.subTitulo +  \" \" + dados.conteudo\n",
    "materias = materias.apply(lambda texto: \"\" if isinstance(texto, float) else limpar_texto(texto).lower())\n",
    "ids = dados.idNoticia\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizando conteúdo\n",
    "Criando tokens com cada palavra do texto para que posteriormente possam ser indexadas e associadas aos respectivos ids das notícias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = materias.apply(nltk.word_tokenize)\n",
    "term_frequence = tokens.apply(Counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexando tokens\n",
    "Criando indices invertidos com os tokens para poder aplicar os métodos de busca "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = {}\n",
    "\n",
    "for i in range(len(tokens)):\n",
    "    id_noticia = ids[i]\n",
    "    palavras = tokens[i]\n",
    "    for palavra in palavras:\n",
    "        palavra = palavra.lower()\n",
    "        if palavra not in index:\n",
    "            index[palavra] = {}\n",
    "        \n",
    "        id_rec = index[palavra].get(id_noticia)\n",
    "        \n",
    "        if not id_rec:\n",
    "            docs = index[palavra]\n",
    "            docs[id_noticia] = term_frequence[i][palavra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gera_vetor_binario(frase):\n",
    "    termos = frase.split(\" \")\n",
    "    doc_binario = {}\n",
    "    \n",
    "    for i in range(len(termos)):\n",
    "        termo = termos[i]\n",
    "        docs = index[termo]\n",
    "        for doc_id in docs:\n",
    "            \n",
    "            if doc_id not in doc_binario:\n",
    "                doc_binario[doc_id] = np.array([0 if j != i else 1 for j in range(len(termos))])\n",
    "            else:\n",
    "                doc_vector = doc_binario[doc_id]\n",
    "                doc_binario[doc_id] = np.array([doc_vector[j] if j != i else 1 for j in range(len(termos))])\n",
    "    \n",
    "    return doc_binario\n",
    "\n",
    "\n",
    "def gera_tf_vetor(frase):\n",
    "    termos = frase.split(\" \")\n",
    "    doc_tf = {}\n",
    "    \n",
    "    for i in range(len(termos)):\n",
    "        termo = termos[i]\n",
    "        docs = index[termo]\n",
    "        for doc_id in docs:\n",
    "            tf = docs[doc_id]\n",
    "            \n",
    "            if doc_id not in doc_tf:\n",
    "                doc_tf[doc_id] = np.array([0 if j != i else tf for j in range(len(termos))])\n",
    "            else:\n",
    "                doc_vector = doc_tf[doc_id]\n",
    "                doc_tf[doc_id] = np.array([doc_vector[j] if j != i else tf for j in range(len(termos))])\n",
    "        \n",
    "    return doc_tf\n",
    "\n",
    "def gera_idf_vetor(frase):\n",
    "    termos = frase.split(\" \")\n",
    "    idf_vector = np.array([math.log((len(materias)+1)/len(index[termo])) for termo in termos])\n",
    "    return idf_vector\n",
    "\n",
    "def gera_query_vetor(frase):\n",
    "    termos = frase.split(\" \")\n",
    "    vetor = np.array([1 if index.get(termo) else 0 for termo in termos])\n",
    "    return vetor\n",
    "\n",
    "def gera_bm25_vetor(frase):\n",
    "    docs_tf = gera_tf_vetor(frase)\n",
    "    k = 5\n",
    "    bm25_vetor = {doc_id: np.array([((k+1)*tf)/(tf+k) for tf in tf_vetor]) for doc_id, tf_vetor in docs_tf.items()}\n",
    "    return bm25_vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def busca_binaria(frase):\n",
    "    docs_bin = gera_vetor_binario(frase)\n",
    "    query = gera_query_vetor(frase)\n",
    "    \n",
    "    doc_rank = sorted(list(docs_bin.items()), key=lambda doc: np.dot(doc[1], query), reverse=True)[:5] \n",
    "    return [doc[0] for doc in doc_rank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_por_tf(frase):\n",
    "    docs_tf = gera_tf_vetor(frase)\n",
    "    query = gera_query_vetor(frase)\n",
    "    \n",
    "    doc_rank = sorted(list(docs_tf.items()), key=lambda doc: np.dot(doc[1], query), reverse=True)[:5] \n",
    "    return [doc[0] for doc in doc_rank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_por_tf_idf(frase):\n",
    "    docs_tf = gera_tf_vetor(frase)\n",
    "    idf = gera_idf_vetor(frase)\n",
    "    \n",
    "    doc_rank = sorted(list(docs_tf.items()), key=lambda doc: np.dot(doc[1], idf), reverse=True)[:5]\n",
    "    return [doc[0] for doc in doc_rank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_por_bm25(frase):\n",
    "    docs_bm25 = gera_bm25_vetor(frase)\n",
    "    idf = gera_idf_vetor(frase)\n",
    "    \n",
    "    doc_rank = sorted(list(docs_bm25.items()), key=lambda doc: np.dot(doc[1], idf), reverse=True)[:5]\n",
    "    return [doc[0] for doc in doc_rank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24\n",
      "0.6519999999999999\n",
      "0.616\n",
      "0.7539999999999999\n",
      "0.04\n",
      "0.048\n",
      "0.057999999999999996\n",
      "0.128\n"
     ]
    }
   ],
   "source": [
    "busca_bin = [busca_binaria(limpar_texto(frase)) for frase in gabarito.str_busca]\n",
    "busca_tf = [buscar_por_tf(limpar_texto(frase)) for frase in gabarito.str_busca]\n",
    "busca_tfidf = [buscar_por_tf_idf(limpar_texto(frase)) for frase in gabarito.str_busca]\n",
    "busca_bm25 = [buscar_por_bm25(limpar_texto(frase)) for frase in gabarito.str_busca]\n",
    "print(mapk(gabarito.busca_binaria, busca_bin, k=5))\n",
    "print(mapk(gabarito.tf, busca_tf, k=5))\n",
    "print(mapk(gabarito.tfidf, busca_tfidf, k=5))\n",
    "print(mapk(gabarito.bm25, busca_bm25, k=5))\n",
    "print(mapk(gabarito.google, busca_bin, k=5))\n",
    "print(mapk(gabarito.google, busca_tf, k=5))\n",
    "print(mapk(gabarito.google, busca_tfidf, k=5))\n",
    "print(mapk(gabarito.google, busca_bm25, k=5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
